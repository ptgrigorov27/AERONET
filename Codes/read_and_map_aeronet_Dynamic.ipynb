{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- **Module:** read_and_map_aeronet.ipynb\n",
        "- **Authors:** Petar Grigorov, Alqamah Sayeed, and Pawan Gupta\n",
        "- **Organization:**NASA AERONET (https://aeronet.gsfc.nasa.gov/)\n",
        "- **Date:**06/18/2023\n",
        "- **Purpose:** to access and map the AERONET data\n",
        "- **Disclaimer:** The code is for demonstration purposes only. Users are responsible to check for accuracy and revise to fit their objective.\n",
        "- **Contact:** report any concern or question related to the code to pawan.gupta@nasa.gov or petar.t.grigorov@nasa.gov"
      ],
      "metadata": {
        "id": "_JoDqu-wN15W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Required packages installation and importing**"
      ],
      "metadata": {
        "id": "CzzFuiyGzBEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install requests\n",
        "!pip install geopandas\n",
        "\n",
        "from bs4 import BeautifulSoup      #reads data from website (web scraping)\n",
        "import requests                    #useful for sending HTTP requests using python\n",
        "import shutil                      #useful for creating zip files\n",
        "import numpy as np                 #for array manipulation\n",
        "import datetime                    #for time data manipulation\n",
        "import pandas as pd                #for data querying and processing\n",
        "import geopandas as gpd            #same as pandas, but for geospatial data\n",
        "import folium                      #Python data visualization on interactive leaflet map\n",
        "import branca                      #similar to folium, but with extra features\n",
        "import branca.colormap as cm       #adds colormap patterns for the map colorbars\n",
        "\n",
        "from copy import deepcopy as dc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "RdEwG0LLR4KW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13764168-6025-4644-f362-7155ecd8ab1a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.4.post1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (23.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.5.3)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.0)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (2023.7.22)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connecting and mounting local drive onto colab notebook**"
      ],
      "metadata": {
        "id": "8ulHy6DWzVFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files      #ensures output zip file can be downloaded\n",
        "from google.colab import drive      #imports local google drive\n",
        "drive.mount('/drive')               #mounts local google drive onto colab\n",
        "!mkdir Output                       #makes directory where output files will be stored"
      ],
      "metadata": {
        "id": "Fe9Drz39Sqrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4f8e03-62ef-4b4f-f8da-1b96fb4bba87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup input parameters such as date, data level, averaging type, AOD range for mapping, AOD/Angstrom exponent, and geographical limits**"
      ],
      "metadata": {
        "id": "5CSmQFb4zpzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_initial = '20230626'                 #starting date YYYYMMDD format\n",
        "dt_final = '20230702'                   #final date YYYYMMDD format\n",
        "level = 1.5                             #AERONET data level\n",
        "average_type = 1                        #daily (1), hourly (2), timeavg (3)\n",
        "vis_min = 0.0                           #any AOD/AE with smaller value will show as green on the color map, adjust as necessary\n",
        "vis_max = 1.0                           #any AOD/AE with larger value will show as red on the color map, adjust as necessary\n",
        "feature_choice = 1                      #Enter '1' if you are specifying an AOD wavelength or '2' if you are specifying an Angstrom exponent\n",
        "wavelength = 500                        #Available choices: 1640, 1020, 870, 865, 779, 675, 667, 620, 560, 555, 551, 532, 531, 510, 500, 490, 443, 440, 412, 400, 380, 340\n",
        "Angstrom_exp = '440-675'                #Available choices: '440-870','380-500','440-675','500-870','340-440','440-675'\n",
        "long_west,long_east = -135,-65          #Enter longitude bounds\n",
        "lat_south,lat_north = 23,53             #Enter latitude bounds"
      ],
      "metadata": {
        "id": "I6XmP_2cDQf1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get desired AERONET data using web services, then scraping data from website**"
      ],
      "metadata": {
        "id": "eQ1YfMOPDV0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yr_initial = dt_initial[:4]               #initial year\n",
        "mon_initial = dt_initial[4:6]             #initial month\n",
        "day_initial = dt_initial[6:]              #initial day\n",
        "\n",
        "yr_final = dt_final[:4]                   #final year\n",
        "mon_final = dt_final[4:6]                 #final month\n",
        "day_final = dt_final[6:]                  #final day\n",
        "\n",
        "if level == 1 or level == 1.0:\n",
        "  level = 10\n",
        "elif level == 1.5:\n",
        "  level = 15\n",
        "elif level == 2 or level == 2.0:\n",
        "  level = 20\n",
        "else:\n",
        "  print(\"\\nIncorrect input for data level type. Defaulting to level 1.5...\")\n",
        "  level = 15\n",
        "\n",
        "if average_type == 1:           #sets up time range bounds based on average type\n",
        "  max_days = 30                 #for daily averages, data cannot exceed a month\n",
        "elif average_type == 2:         #for hourly averages, data cannot exceed a week\n",
        "  max_days = 7                  #for site averages, time range is unlimited\n",
        "elif average_type == 3:         #If the input is wrong, program defaults to daily averages\n",
        "  max_days = 9999999999999\n",
        "else:\n",
        "  average_type = 1\n",
        "  max_days = 30\n",
        "  print(\"\\nIncorrect input for average type. Defaulting to daily averages (1)...\")\n",
        "\n",
        "if vis_min < 0 or vis_max <= 0:\n",
        "  vis_min = 0\n",
        "  vis_max = 1\n",
        "  print(\"\\nIncorrect entry. Numbers cannot be negative. Defaulting to [0,1] range...\")\n",
        "elif vis_min >= vis_max:         #if someone accidentally switches the colorbar limits, where the max is he smaller number, the values are swapped.\n",
        "  vis_min = 0\n",
        "  vis_max = 1\n",
        "  print(\"\\nColorbar limit input does not match format. Lower bound cannot be greater than the upper. Defaulting to [0,1] range..\")\n",
        "if level == 20 and int(yr_initial) == datetime.date.today().year:                 #if user wants level 2 data for the current year, program alerts that data may not be available\n",
        "  level = 15                                                                      #defaults to level 1.5 data\n",
        "  print(\"\\nThere is no level 2 data available for the current year. Defaulting to level 1.5 data...\")\n",
        "\n",
        "date_initial = pd.to_datetime(dt_initial)\n",
        "date_final = pd.to_datetime(dt_final)\n",
        "delta = date_final - date_initial\n",
        "\n",
        "if delta.days > max_days:\n",
        "  print(\"\\nNote that the selected time frame is too large, which may cause the program to crash.\")\n",
        "\n",
        "base_web = 'https://aeronet.gsfc.nasa.gov/cgi-bin/print_web_data_v3?year=',yr_initial,'&month=',mon_initial,'&day=',day_initial,'&year2=',yr_final,'&month2=',mon_final,'&day2=',day_final,'&AOD',level,'=1&AVG=10'\n",
        "\n",
        "def convertTuple(tup):              #this function converts the url above from tuple to a string. It basically removes the commas.\n",
        "    st = ''.join(map(str, tup))\n",
        "    return st\n",
        "\n",
        "url = convertTuple(base_web)        #URL tuple is passed, and converted to string\n",
        "\n",
        "soup = BeautifulSoup(requests.get(url).text) #web services contents are read here from URL\n",
        "\n",
        "if len(soup) <= 1:                    #alerts the user if the data cannot be read due to improper parameter inputs\n",
        "  print(\"\\nThe link could not be generated due to issues with the input. Please try again.\")"
      ],
      "metadata": {
        "id": "Z8AgFuQ8Sxy_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read and filter downloaded data as per user average type specification**"
      ],
      "metadata": {
        "id": "ceWvm1KA00QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(r'/content/sample_data/Test.txt' ,\"w\") as oFile:          #writes the data scraped from \"beautiful soup\" to a text file on your local Google drive\n",
        "    oFile.write(str(soup.text))\n",
        "    oFile.close()\n",
        "\n",
        "df = pd.read_csv(r'/content/sample_data/Test.txt',skiprows = 5)     #loads the csv data into a Pandas dataframe\n",
        "df = df.replace(-999.0, np.nan)                                     #replaces all -999.0 vakyes with NaN; helps with accurate data aggregation\n",
        "df.rename(columns={'Site_Latitude(Degrees)': 'Site_Latitude', 'Site_Longitude(Degrees)': 'Site_Longitude'}, inplace = True)\n",
        "df[['Day','Month','Year']] = df['Date(dd:mm:yyyy)'].str.split(':',expand=True)                                #splits the date column and then joins it back together using \"-\" instead of \":\"\n",
        "df['Date'] = df[['Year','Month','Day']].apply(lambda x: '-'.join(x.values.astype(str)), axis=\"columns\")       #because datetime format in python does not recognize colons\n",
        "df = df.drop(columns=['Year','Month','Day','Date(dd:mm:yyyy)'])                     #drops the old date columns, only keeps the new one\n",
        "df.insert(1, 'Date', df.pop('Date'))                                                #moves the new Date column to the front of the data frame\n",
        "df['Date']= pd.to_datetime(df['Date'])                                              #converts the new date column to datetime format\n",
        "\n",
        "if average_type == 1:\n",
        "  df = df.drop(columns=['Time(hh:mm:ss)'])                              #If user wants daily averages, the \"Time\" column is redundant and will be dropped from the data frame\n",
        "  df = df.groupby(['AERONET_Site', 'Date']).mean()                      #The \"groupby\" function is used to obtain average daily (or hourly) AOD wavelength for each AERONET site.                                                                 # np.mean() function is used to compute the arithmetic average of the array ignoring the NaN value\n",
        "elif average_type == 2:\n",
        "  df['Hour'] = np.nan                                                   #This code creates a blank column \"Hour\".\n",
        "  for i in range(len(df['Time(hh:mm:ss)'])):                            #The following for-loop truncates the last 6 characters of the Time(hh:mm:ss) column and assigns them to the new \"Hour\" column.\n",
        "    df['Hour'][i] = df['Time(hh:mm:ss)'][i][:-6]                        #That way that new column only has the hours, while minutes and seconds are truncated.\n",
        "  df.insert(3, 'Hour', df.pop('Hour'))                                  #The original Time column is kept in the dataframe.\n",
        "  df = df.groupby(['AERONET_Site', 'Date','Hour']).mean()\n",
        "elif average_type == 3:\n",
        "  df = df.drop(columns=['Day_of_Year', 'Day_of_Year(Fraction)'])       #if the site averages are selected, the day of year, date and hour are now redundant. Instead, the code\n",
        "  df = df.groupby(['AERONET_Site']).mean()                             #groups dataset by the Aeronet site location, and takes the total time average for each location"
      ],
      "metadata": {
        "id": "aJ8zNaz5S48f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AOD Wavelength or Angstrom Exponent Selection**"
      ],
      "metadata": {
        "id": "AQPcXhn81AEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AOD_col = ['AOD_1640nm','AOD_1020nm','AOD_870nm','AOD_865nm','AOD_779nm','AOD_675nm','AOD_667nm','AOD_620nm','AOD_560nm',\n",
        "       'AOD_555nm','AOD_551nm','AOD_532nm','AOD_531nm','AOD_510nm','AOD_500nm','AOD_490nm','AOD_443nm','AOD_440nm',\n",
        "       'AOD_412nm','AOD_400nm','AOD_380nm','AOD_340nm']                                                   #list of AOD columns, used for mapping user input to them\n",
        "\n",
        "Ang_exp_col = ['440-870_Angstrom_Exponent','380-500_Angstrom_Exponent','440-675_Angstrom_Exponent',\n",
        "               '500-870_Angstrom_Exponent','340-440_Angstrom_Exponent','440-675_Angstrom_Exponent']       #list of Angstrom Exponent columns, used for mapping user input to them\n",
        "\n",
        "AOD_val = [1640, 1020, 870, 865, 779, 675, 667, 620, 560, 555, 551, 532, 531, 510, 500, 490, 443, 440, 412, 400, 380, 340]   #expected user input choices for AOD\n",
        "Ang_exp_val = ['440-870','380-500','440-675','500-870','340-440','440-675']                                                  #expected user input choices for AE\n",
        "\n",
        "if feature_choice == 1:\n",
        "  if wavelength in AOD_val:             #if user input for AOD wavelength matches a value in the list, code proceeds forward. Otherwise it prompts user to try again\n",
        "    for i in range(len(AOD_col)):\n",
        "      if wavelength == AOD_val[i]:      #code scans the list of columns and list of possible values, and matches user input to the appropriate column name\n",
        "        df = df[['Site_Latitude','Site_Longitude', AOD_col[i]]]         #if a match exists, the column name is matched to the actual column and it is then appended to the dataset\n",
        "  else:\n",
        "    df = df[['Site_Latitude','Site_Longitude','AOD_500nm']]\n",
        "    print(\"\\nInput for AOD wavelength is not in list. Defaulting to 500nm...\")\n",
        "elif feature_choice == 2:\n",
        "  if Angstrom_exp in Ang_exp_val:     #if user input for Angstrom Exponent matches a value in the list, code proceeds forward. Otherwise it prompts user to try again\n",
        "    for i in range(len(Ang_exp_col)):\n",
        "      if Angstrom_exp == Ang_exp_val[i]:  #code scans the list of columns and list of possible values, and matches user input to the appropriate column nam\n",
        "        df = df[['Site_Latitude','Site_Longitude', Ang_exp_col[i]]]     #if a match exists, the column name is matched to the actual column and it is then appended to the dataset\n",
        "  else:\n",
        "    df = df[['Site_Latitude','Site_Longitude','440-675']]\n",
        "    print(\"\\nInput for Angstrom Exponent is not in list. Defaulting to 440-675...\")\n",
        "else:\n",
        "  feature_choice == 1\n",
        "  print(\"\\nIncorrect input for feature choice. Defaulting to AOD wavelength (1)...\")\n",
        "  if wavelength in AOD_val:             #if user input for AOD wavelength matches a value in the list, code proceeds forward. Otherwise it prompts user to try again\n",
        "    for i in range(len(AOD_col)):\n",
        "      if wavelength == AOD_val[i]:      #code scans the list of columns and list of possible values, and matches user input to the appropriate column name\n",
        "        df = df[['Site_Latitude','Site_Longitude', AOD_col[i]]]         #if a match exists, the column name is matched to the actual column and it is then appended to the dataset\n",
        "  else:\n",
        "    df = df[['Site_Latitude','Site_Longitude','AOD_500nm']]\n",
        "    print(\"\\nInput for AOD wavelength is not in list. Defaulting to 500nm...\")\n",
        "\n",
        "df = df.dropna() #Drops NaN or -999.0 values"
      ],
      "metadata": {
        "id": "ceE04Eg9S8ca"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Specify geographical coordinates to zoom into area of interest.**"
      ],
      "metadata": {
        "id": "zCpqkwmxCXrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if lat_south > lat_north:\n",
        "  print(\"\\nGeographical input does not match format. Defaulting to world map...\")\n",
        "  lat_south = -90\n",
        "  lat_north = 90\n",
        "\n",
        "if long_west > long_east:\n",
        "  print(\"\\nGeographical input does not match format. Defaulting to world map...\")\n",
        "  long_west = -180\n",
        "  long_east = 180\n",
        "\n",
        "df = df[(df['Site_Latitude'] >= lat_south) & (df['Site_Latitude'] <= lat_north)]                  #filters new dataframe to AERONET sites within the geographical bounds\n",
        "df = df[(df['Site_Longitude'] >= long_west) & (df['Site_Longitude'] <= long_east)]\n",
        "df = df.reset_index()"
      ],
      "metadata": {
        "id": "PeO7NbcaCXTS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dynamic Map**"
      ],
      "metadata": {
        "id": "A-ZZpSQ4HkIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "geometry = gpd.points_from_xy(df.Site_Longitude, df.Site_Latitude)\n",
        "geo_df = gpd.GeoDataFrame(df, geometry=geometry).reset_index()\n",
        "colormap = cm.LinearColormap(colors=['green','yellow','orange','red'],\n",
        "                             index=[0,0.25,0.5,1],vmin=vis_min,vmax=vis_max).to_step(n=200, method='log')\n",
        "\n",
        "if average_type == 1:\n",
        "  date_list = geo_df[['Date']].astype(str)\n",
        "  date_list = date_list.to_numpy()\n",
        "  date_list = np.unique(date_list)\n",
        "\n",
        "  for i in range(len(date_list)):\n",
        "    geo_df = gpd.GeoDataFrame(df, geometry=geometry).reset_index()\n",
        "    geo_df = geo_df.loc[geo_df['Date'] == date_list[i]].reset_index(drop=True)\n",
        "    map = folium.Map(location=[((lat_south+lat_north)/2), ((long_west+long_east)/2)], tiles=\"Stamen Terrain\", zoom_start = 4)\n",
        "\n",
        "    lat = list(geo_df.Site_Latitude)\n",
        "    lon = list(geo_df.Site_Longitude)\n",
        "    pow = list(geo_df.iloc[:,-2])\n",
        "\n",
        "    for loc, p in zip(zip(lat, lon), pow):\n",
        "        folium.CircleMarker(\n",
        "            location=loc,\n",
        "            radius=50,\n",
        "            fill=True,\n",
        "            color=colormap(p),\n",
        "            fill_opacity=0.8\n",
        "        ).add_to(map)\n",
        "\n",
        "    map.add_child(colormap)\n",
        "\n",
        "    geo_df_list = [[point.xy[1][0], point.xy[0][0]] for point in geo_df.geometry]\n",
        "    geo_df_list = np.around(np.array(geo_df_list),6)\n",
        "    geo_list_df = pd.DataFrame(geo_df_list, columns = ['lat','long'])\n",
        "    geo_list_df = geo_list_df.drop_duplicates(subset=['lat']).reset_index(drop=True)\n",
        "    geo_df_list = geo_list_df.values.tolist()\n",
        "\n",
        "    j = 0\n",
        "    for coordinates in geo_df_list:\n",
        "      map.add_child(folium.Marker(location=geo_df_list[j],\n",
        "                popup=\"Site: \"\n",
        "                + str(geo_df.AERONET_Site[j])\n",
        "                + \"<br>\"\n",
        "                + \"Coordinates: \"\n",
        "                + str(geo_df_list[j])\n",
        "                + \"<br>\"\n",
        "                + geo_df.columns[-2]\n",
        "                + \" (site avg): \"\n",
        "                + str(geo_df.iloc[j,-2].round(6))))\n",
        "      j = j + 1\n",
        "\n",
        "    map.save('/content/Output/Map_'+str(date_list[i])+'.html')\n",
        "\n",
        "elif average_type == 2:\n",
        "  geo_df['Hour'] = pd.to_datetime(geo_df['Hour'].astype(str), format='%H')\n",
        "  geo_df['Hour'] = geo_df['Hour'].dt.time\n",
        "  geo_df['Date_Time'] = geo_df.apply(lambda x : pd.datetime.combine(x['Date'],x['Hour']),1)\n",
        "  geo_df.insert(3, 'Date_Time', geo_df.pop('Date_Time'))\n",
        "  geo_df = geo_df.drop(columns=['Date', 'Hour'])\n",
        "\n",
        "  date_list = geo_df[['Date_Time']].astype(str)\n",
        "  date_list = date_list.to_numpy()\n",
        "  date_list = np.unique(date_list)\n",
        "\n",
        "  for i in range(len(date_list)):\n",
        "    geo_df = gpd.GeoDataFrame(df, geometry=geometry).reset_index()\n",
        "    geo_df['Hour'] = pd.to_datetime(geo_df['Hour'].astype(str), format='%H')\n",
        "    geo_df['Hour'] = geo_df['Hour'].dt.time\n",
        "    geo_df['Date_Time'] = geo_df.apply(lambda x : pd.datetime.combine(x['Date'],x['Hour']),1)\n",
        "    geo_df.insert(3, 'Date_Time', geo_df.pop('Date_Time'))\n",
        "    geo_df = geo_df.drop(columns=['Date', 'Hour'])\n",
        "    geo_df = geo_df.loc[geo_df['Date_Time'] == date_list[i]].reset_index(drop=True)\n",
        "\n",
        "    map = folium.Map(location=[((lat_south+lat_north)/2), ((long_west+long_east)/2)], tiles=\"Stamen Terrain\", zoom_start = 4)\n",
        "\n",
        "    lat = list(geo_df.Site_Latitude)\n",
        "    lon = list(geo_df.Site_Longitude)\n",
        "    pow = list(geo_df.iloc[:,-2])\n",
        "\n",
        "    for loc, p in zip(zip(lat, lon), pow):\n",
        "        folium.CircleMarker(\n",
        "            location=loc,\n",
        "            radius=50,\n",
        "            fill=True,\n",
        "            color=colormap(p),\n",
        "            fill_opacity=0.8\n",
        "        ).add_to(map)\n",
        "\n",
        "    map.add_child(colormap)\n",
        "\n",
        "    geo_df_list = [[point.xy[1][0], point.xy[0][0]] for point in geo_df.geometry]\n",
        "    geo_df_list = np.around(np.array(geo_df_list),6)\n",
        "    geo_list_df = pd.DataFrame(geo_df_list, columns = ['lat','long'])\n",
        "    geo_list_df = geo_list_df.drop_duplicates(subset=['lat']).reset_index(drop=True)\n",
        "    geo_df_list = geo_list_df.values.tolist()\n",
        "\n",
        "    j = 0\n",
        "    for coordinates in geo_df_list:\n",
        "      map.add_child(folium.Marker(location=geo_df_list[j],\n",
        "                popup=\"Site: \"\n",
        "                + str(geo_df.AERONET_Site[j])\n",
        "                + \"<br>\"\n",
        "                + \"Coordinates: \"\n",
        "                + str(geo_df_list[j])\n",
        "                + \"<br>\"\n",
        "                + geo_df.columns[-2]\n",
        "                + \" (site avg): \"\n",
        "                + str(geo_df.iloc[j,-2].round(6))))\n",
        "      j = j + 1\n",
        "\n",
        "    map.save('/content/Output/Map_'+str(date_list[i][:-6])+'.html')\n",
        "\n",
        "elif average_type == 3:\n",
        "  map = folium.Map(location=[((lat_south+lat_north)/2), ((long_west+long_east)/2)], tiles=\"Stamen Terrain\", zoom_start = 4)\n",
        "\n",
        "  lat = list(geo_df.Site_Latitude)\n",
        "  lon = list(geo_df.Site_Longitude)\n",
        "  pow = list(geo_df.iloc[:,-2])\n",
        "\n",
        "  for loc, p in zip(zip(lat, lon), pow):\n",
        "      folium.CircleMarker(\n",
        "          location=loc,\n",
        "          radius=50,\n",
        "          fill=True,\n",
        "          color=colormap(p),\n",
        "          fill_opacity=0.8\n",
        "      ).add_to(map)\n",
        "\n",
        "  map.add_child(colormap)\n",
        "\n",
        "  geo_df_list = [[point.xy[1][0], point.xy[0][0]] for point in geo_df.geometry]\n",
        "  geo_df_list = np.around(np.array(geo_df_list),6)\n",
        "  geo_list_df = pd.DataFrame(geo_df_list, columns = ['lat','long'])\n",
        "  geo_list_df = geo_list_df.drop_duplicates(subset=['lat']).reset_index(drop=True)\n",
        "  geo_df_list = geo_list_df.values.tolist()\n",
        "\n",
        "  j = 0\n",
        "  for coordinates in geo_df_list:\n",
        "    map.add_child(folium.Marker(location=geo_df_list[j],\n",
        "              popup=\"Site: \"\n",
        "              + str(geo_df.AERONET_Site[j])\n",
        "              + \"<br>\"\n",
        "              + \"Coordinates: \"\n",
        "              + str(geo_df_list[j])\n",
        "              + \"<br>\"\n",
        "              + geo_df.columns[-2]\n",
        "              + \" (site avg): \"\n",
        "              + str(geo_df.iloc[j,-2].round(6))))\n",
        "    j = j + 1\n",
        "\n",
        "  map.save('/content/Output/Map_Site_Average.html')\n",
        "\n",
        "while True:\n",
        "  zip_download = str(input(\"Would you like to download your output in a zipped folder (y or n)?: \"))\n",
        "  if zip_download == 'y' or zip_download == 'Y' or zip_download == 'Yes' or zip_download == 'yes' or zip_download == 'YES':\n",
        "    shutil.make_archive('Output', 'zip', '/content/Output')  #zips all output files\n",
        "    files.download('Output.zip')  #Note: Must use Chrome browser for download to work\n",
        "    break\n",
        "  elif zip_download == 'n' or zip_download == 'N' or zip_download == 'No' or zip_download == 'no' or zip_download == 'NO':\n",
        "    print(\"\\nThanks! I hope you enjoyed the program.\")\n",
        "    break\n",
        "  else:\n",
        "    print(\"\\nIncorrect input. Please try again!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "G5h-BrKEHjSI",
        "outputId": "06d4650f-8c24-4cfd-fbb7-0dc1995c037b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Would you like to download your output in a zipped folder (y or n)?: y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_36397e74-552b-42fe-9d0b-ee00a6198323\", \"Output.zip\", 153185)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}